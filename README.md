Forward and Backward Propagation ile Yapay Sinir AÄŸÄ± EÄŸitimi
Bu proje, YZM212 Makine Ã–ÄŸrenmesi dersi kapsamÄ±nda, temel bir Yapay Sinir AÄŸÄ± (ANN) modeli geliÅŸtirmek amacÄ±yla hazÄ±rlanmÄ±ÅŸtÄ±r. Model, ileri (forward) ve geri (backward) yayÄ±lÄ±m algoritmalarÄ± kullanÄ±larak sÄ±fÄ±rdan oluÅŸturulmuÅŸ, yalnÄ±zca NumPy gibi temel kÃ¼tÃ¼phanelerle gerÃ§ekleÅŸtirilmiÅŸtir. HazÄ±r makine Ã¶ÄŸrenmesi kÃ¼tÃ¼phaneleri (scikit-learn, Keras, PyTorch vb.) kullanÄ±lmamÄ±ÅŸtÄ±r.

 Veri Seti ve Ã–n Ä°ÅŸleme
KullanÄ±lan Veri Seti
Proje kapsamÄ±nda Iris veri seti kullanÄ±lmÄ±ÅŸtÄ±r. Bu veri seti 3 farklÄ± iris Ã§iÃ§eÄŸi tÃ¼rÃ¼ne (Setosa, Versicolor, Virginica) ait 4 Ã¶zellik iÃ§ermektedir:

Sepal Length (cm)

Sepal Width (cm)

Petal Length (cm)

Petal Width (cm)

Ã–n Ä°ÅŸleme AdÄ±mlarÄ±
Eksik Veri KontrolÃ¼: Veri setinde eksik deÄŸer bulunmamaktadÄ±r.

Etiket Kodlama: Ã‡iÃ§ek tÃ¼rleri LabelBinarizer kullanÄ±larak one-hot encoding ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

Ã–zellik Ã–lÃ§ekleme: TÃ¼m Ã¶zellikler Min-Max Normalizasyonu ile [0, 1] aralÄ±ÄŸÄ±na Ã§ekilmiÅŸtir.

Veri AyrÄ±mÄ±: Veri seti eÄŸitim (%80) ve test (%20) olarak ayrÄ±lmÄ±ÅŸtÄ±r.

 Model Mimarisi
Yapay sinir aÄŸÄ± aÅŸaÄŸÄ±daki gibi Ã¼Ã§ katmandan oluÅŸmaktadÄ±r:

Katman	NÃ¶ron SayÄ±sÄ±	Aktivasyon Fonksiyonu
GiriÅŸ KatmanÄ±	4 (Ã¶zellik sayÄ±sÄ±)	-
Gizli Katman	8 (Ã¶rnek)	Sigmoid
Ã‡Ä±kÄ±ÅŸ KatmanÄ±	3 (sÄ±nÄ±f sayÄ±sÄ±)	Softmax

Not: Gizli katman sayÄ±sÄ± ve nÃ¶ron sayÄ±sÄ± parametre olarak deÄŸiÅŸtirilebilir.

Aktivasyon FonksiyonlarÄ±
Sigmoid:
FormÃ¼l: Ïƒ(x) = 1 / (1 + e^(-x))

Softmax:
FormÃ¼l: softmax(xáµ¢) = exp(xáµ¢) / Î£ exp(xâ±¼)

 Modelin Ã‡alÄ±ÅŸma Prensibi
Ä°leri YayÄ±lÄ±m (Forward Propagation)

Girdi, aÄŸÄ±rlÄ±klarla Ã§arpÄ±lÄ±r ve bias eklenir.

Gizli katmandaki Ã§Ä±ktÄ±lar Sigmoid fonksiyonu ile aktive edilir.

Ã‡Ä±kÄ±ÅŸ katmanÄ±na iletilen veriler softmax ile olasÄ±lÄ±k deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

Hata Hesaplama

KayÄ±p fonksiyonu olarak Cross-Entropy Loss kullanÄ±lmÄ±ÅŸtÄ±r:

L = -Î£(y_true Ã— log(y_pred))

Geri YayÄ±lÄ±m (Backpropagation)

Hata, zincir kuralÄ± kullanÄ±larak katmanlara geri yayÄ±lÄ±r.

AÄŸÄ±rlÄ±k ve bias'larÄ±n gradyanlarÄ± hesaplanÄ±r ve gÃ¼ncellenir:

weight = weight - learning_rate Ã— gradient

Gradyan Ä°niÅŸ (Gradient Descent)

AÄŸÄ±rlÄ±klar her epoch sonunda gÃ¼ncellenir.

Ã–ÄŸrenme oranÄ± (learning_rate = 0.1) olarak belirlenmiÅŸtir.

ğŸ‹â€â™€ EÄŸitim SÃ¼reci
Model 1000 epoch boyunca eÄŸitilmiÅŸtir. Her epoch sonunda eÄŸitim kaybÄ± (loss) hesaplanmÄ±ÅŸ ve loss vs epoch grafiÄŸi oluÅŸturulmuÅŸtur.

EÄŸitim Parametreleri
Parametre	DeÄŸer
Epoch	1000
Ã–ÄŸrenme OranÄ±	0.1
Gizli NÃ¶ron SayÄ±sÄ±	8
Aktivasyon	Sigmoid / Softmax

 SonuÃ§lar
KayÄ±p DeÄŸeri (Loss)

EÄŸitim baÅŸlangÄ±cÄ±nda (Epoch 1): yaklaÅŸÄ±k 1.16

EÄŸitim sonunda (Epoch 1000): yaklaÅŸÄ±k 0.04

KayÄ±p eÄŸrisi sÃ¼rekli azalmÄ±ÅŸ ve modelin baÅŸarÄ±yla Ã¶ÄŸrenme gerÃ§ekleÅŸtirdiÄŸi gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.

ğŸ“ˆ Grafikte detaylÄ± olarak gÃ¶sterilmiÅŸtir:
![accuracy_plot](https://github.com/user-attachments/assets/fe03d63a-4f9e-4ad1-b544-66aa4678af38)



KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix)

GerÃ§ek \ Tahmin	Setosa	Versicolor	Virginica
Setosa	10	0	0
Versicolor	0	10	0
Virginica	0	0	10

Toplam doÄŸru sÄ±nÄ±flandÄ±rma: 30 / 30

ğŸ“Š GÃ¶rsel hali:
![confusion_matrix](https://github.com/user-attachments/assets/2774718e-f6bd-46f3-94eb-42db254660de)

Test DoÄŸruluÄŸu (Accuracy)

DoÄŸru sÄ±nÄ±flandÄ±rma oranÄ±: %100.00

(30 test Ã¶rneÄŸinin tamamÄ± doÄŸru sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r.)


 Proje Dosya YapÄ±sÄ±

5.ForwardAndBackwardPropagation/
â”œâ”€â”€ forward_backward_nn.ipynb     # Ana model dosyasÄ± (Jupyter Notebook)
â”œâ”€â”€ dataset.csv                   # KullanÄ±lan veri seti
â”œâ”€â”€ accuracy_plot.png             # Loss vs Epoch grafiÄŸi
â”œâ”€â”€ confusion_matrix.png          # KarmaÅŸÄ±klÄ±k matrisi gÃ¶rseli
â”œâ”€â”€ Readme.md                     # Bu aÃ§Ä±klama dosyasÄ±
â”œâ”€â”€ requirements.txt              # Gerekli kÃ¼tÃ¼phaneler listesi
 KullanÄ±lan KÃ¼tÃ¼phaneler
python
Kopyala
DÃ¼zenle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score
Not: scikit-learn yalnÄ±zca veri bÃ¶lme, etiketleme ve deÄŸerlendirme metrikleri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Model sÄ±fÄ±rdan elle yazÄ±lmÄ±ÅŸtÄ±r.


ğŸ“š KaynakÃ§a
Brownlee, J. (2018). Neural Networks from Scratch in Python. Machine Learning Mastery.
https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/

https://www.youtube.com/watch?v=f26KI43FK58

https://github.com/git-guides/#learning-git-basics
